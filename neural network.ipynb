{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st warm up : neural network\n",
    "# https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#neural-networks\n",
    "\n",
    "# https://pytorch.org/docs/stable/torch.html\n",
    "# https://pytorch.org/docs/stable/autograd.html\n",
    "# https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3)   # 对 1 sample * 6 channels * 3 height * 3 width 的输入应用二维卷积\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        self.fc1 = nn.Linear(16*6*6,120) # 对传入数据应用线性变换：y=xA^T+b\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))    # 对激活后的函数做2d max池化\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1,self.num_flat_features(x))       # resize x 为一位数组 方便下一步线性变换\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.2745, -0.1277, -0.2082],\n",
      "          [ 0.0644,  0.2746, -0.2541],\n",
      "          [ 0.0230, -0.2578, -0.0858]]],\n",
      "\n",
      "\n",
      "        [[[-0.3323,  0.3309, -0.2447],\n",
      "          [-0.0284,  0.3170,  0.1252],\n",
      "          [ 0.1483, -0.0347, -0.2134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3022,  0.1151,  0.2858],\n",
      "          [ 0.3053, -0.0881, -0.1754],\n",
      "          [ 0.0668,  0.2644,  0.1537]]],\n",
      "\n",
      "\n",
      "        [[[-0.2849, -0.0462,  0.1934],\n",
      "          [-0.1086, -0.2841,  0.2755],\n",
      "          [ 0.2402,  0.2392,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2022,  0.3099,  0.2514],\n",
      "          [-0.0503, -0.0478, -0.2278],\n",
      "          [-0.1114,  0.0346, -0.3323]]],\n",
      "\n",
      "\n",
      "        [[[-0.1701, -0.2107, -0.2377],\n",
      "          [-0.0774, -0.2030, -0.0778],\n",
      "          [-0.3244,  0.1019,  0.1465]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1178, -0.2793, -0.2101,  0.0639,  0.0278, -0.2797],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.1073, -0.0021, -0.0224],\n",
      "          [-0.0808,  0.0549, -0.0980],\n",
      "          [ 0.0091,  0.0319, -0.1260]],\n",
      "\n",
      "         [[-0.1066,  0.0554,  0.0787],\n",
      "          [ 0.0287, -0.0156,  0.1045],\n",
      "          [-0.1094,  0.1102, -0.0196]],\n",
      "\n",
      "         [[ 0.1273, -0.1111, -0.0945],\n",
      "          [-0.0978,  0.0548, -0.1330],\n",
      "          [ 0.0530,  0.0535,  0.0594]],\n",
      "\n",
      "         [[ 0.1293,  0.1009,  0.0543],\n",
      "          [ 0.1285,  0.1028, -0.1060],\n",
      "          [ 0.1241, -0.1096, -0.0913]],\n",
      "\n",
      "         [[-0.0328,  0.0688, -0.0293],\n",
      "          [ 0.0086,  0.0658,  0.0340],\n",
      "          [ 0.1129, -0.0696,  0.0568]],\n",
      "\n",
      "         [[-0.0634,  0.0788,  0.0993],\n",
      "          [-0.0395,  0.0758, -0.1135],\n",
      "          [-0.1143,  0.0265,  0.0777]]],\n",
      "\n",
      "\n",
      "        [[[-0.0699,  0.0002,  0.0652],\n",
      "          [-0.1342,  0.0687,  0.0245],\n",
      "          [-0.0314,  0.0095,  0.1110]],\n",
      "\n",
      "         [[-0.0823, -0.0354, -0.0553],\n",
      "          [ 0.1144, -0.0166, -0.0992],\n",
      "          [-0.0395, -0.0093, -0.0509]],\n",
      "\n",
      "         [[-0.0303,  0.0214, -0.0263],\n",
      "          [ 0.0006,  0.1080,  0.0933],\n",
      "          [ 0.0937,  0.0484,  0.1082]],\n",
      "\n",
      "         [[-0.0988,  0.0595,  0.0957],\n",
      "          [-0.1251,  0.1050, -0.0393],\n",
      "          [ 0.0877, -0.0459, -0.0813]],\n",
      "\n",
      "         [[ 0.0351, -0.0431, -0.1137],\n",
      "          [-0.0552, -0.0884, -0.0752],\n",
      "          [-0.0977, -0.0862,  0.1156]],\n",
      "\n",
      "         [[-0.0298, -0.0949, -0.1006],\n",
      "          [-0.0541, -0.0992,  0.0871],\n",
      "          [-0.0502,  0.0276,  0.0894]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0854,  0.1037,  0.1221],\n",
      "          [ 0.0123, -0.0692,  0.0667],\n",
      "          [ 0.0759, -0.0641,  0.0707]],\n",
      "\n",
      "         [[ 0.0468, -0.1063,  0.0500],\n",
      "          [-0.0132, -0.0907, -0.1241],\n",
      "          [ 0.1324, -0.1338,  0.0031]],\n",
      "\n",
      "         [[-0.1185, -0.1093, -0.0836],\n",
      "          [ 0.0415,  0.0972,  0.0723],\n",
      "          [-0.0511,  0.0075,  0.1050]],\n",
      "\n",
      "         [[-0.0815, -0.0946, -0.0590],\n",
      "          [ 0.0097, -0.0364,  0.1032],\n",
      "          [ 0.0536,  0.0571,  0.0290]],\n",
      "\n",
      "         [[-0.0360,  0.0848,  0.0804],\n",
      "          [ 0.0986, -0.1140, -0.0617],\n",
      "          [-0.1340,  0.0894, -0.0501]],\n",
      "\n",
      "         [[-0.0633, -0.1271, -0.0896],\n",
      "          [ 0.0274, -0.0864,  0.1148],\n",
      "          [ 0.0260,  0.0929,  0.0600]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0073, -0.0941, -0.0035],\n",
      "          [ 0.1312,  0.0039, -0.0789],\n",
      "          [-0.0426,  0.1349,  0.1039]],\n",
      "\n",
      "         [[ 0.0208, -0.0141, -0.1124],\n",
      "          [ 0.0188,  0.1342,  0.0325],\n",
      "          [ 0.0557, -0.0172,  0.0089]],\n",
      "\n",
      "         [[ 0.0622, -0.1161,  0.0718],\n",
      "          [-0.0489,  0.0572,  0.0145],\n",
      "          [ 0.0036,  0.1324,  0.0959]],\n",
      "\n",
      "         [[ 0.0992, -0.0497,  0.0830],\n",
      "          [-0.0986,  0.0068,  0.0192],\n",
      "          [-0.0490,  0.0893, -0.0315]],\n",
      "\n",
      "         [[ 0.0216,  0.0684, -0.0091],\n",
      "          [ 0.0812, -0.1017,  0.0733],\n",
      "          [-0.0529,  0.1386, -0.0431]],\n",
      "\n",
      "         [[ 0.0545, -0.0337,  0.1273],\n",
      "          [-0.0579,  0.1277,  0.0374],\n",
      "          [-0.1018,  0.0318,  0.0635]]],\n",
      "\n",
      "\n",
      "        [[[-0.0007,  0.0365,  0.0056],\n",
      "          [ 0.0776,  0.0389, -0.1246],\n",
      "          [-0.1335, -0.0093, -0.0573]],\n",
      "\n",
      "         [[-0.1269, -0.0249,  0.0044],\n",
      "          [-0.1195, -0.1266,  0.0530],\n",
      "          [-0.1195,  0.0751,  0.1324]],\n",
      "\n",
      "         [[ 0.0447,  0.0958,  0.1350],\n",
      "          [ 0.0199,  0.0917, -0.1095],\n",
      "          [ 0.0841, -0.0259, -0.0369]],\n",
      "\n",
      "         [[-0.0118, -0.0363,  0.0327],\n",
      "          [ 0.0853, -0.0327, -0.0270],\n",
      "          [ 0.0554,  0.0927,  0.1368]],\n",
      "\n",
      "         [[-0.0353,  0.1359, -0.0045],\n",
      "          [-0.0973, -0.1282, -0.0028],\n",
      "          [-0.0239, -0.1304,  0.1063]],\n",
      "\n",
      "         [[ 0.0754, -0.0081, -0.0338],\n",
      "          [ 0.0263, -0.0879, -0.0703],\n",
      "          [-0.0052, -0.0590, -0.0800]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0659, -0.0688, -0.0389],\n",
      "          [ 0.0175, -0.0039,  0.0798],\n",
      "          [ 0.0360, -0.1044, -0.1226]],\n",
      "\n",
      "         [[ 0.0495, -0.1282,  0.0568],\n",
      "          [ 0.0549, -0.0533, -0.0160],\n",
      "          [-0.0273,  0.1343, -0.1012]],\n",
      "\n",
      "         [[-0.1184, -0.0445,  0.0015],\n",
      "          [ 0.0978,  0.1279, -0.0161],\n",
      "          [-0.0153,  0.0070, -0.1270]],\n",
      "\n",
      "         [[-0.0875,  0.1344, -0.1044],\n",
      "          [ 0.0777, -0.1058, -0.0264],\n",
      "          [ 0.0560, -0.1036, -0.0871]],\n",
      "\n",
      "         [[-0.0906,  0.0772, -0.0183],\n",
      "          [-0.0888, -0.1238,  0.1152],\n",
      "          [-0.0949, -0.0614,  0.0492]],\n",
      "\n",
      "         [[ 0.0092, -0.0732,  0.0251],\n",
      "          [ 0.0414,  0.0850,  0.0767],\n",
      "          [ 0.1132,  0.0169, -0.0212]]],\n",
      "\n",
      "\n",
      "        [[[-0.1057, -0.0155, -0.0475],\n",
      "          [ 0.0922, -0.1071, -0.0443],\n",
      "          [ 0.0983,  0.1278,  0.0981]],\n",
      "\n",
      "         [[ 0.0770,  0.0606,  0.0527],\n",
      "          [ 0.0287, -0.1279, -0.0191],\n",
      "          [ 0.1090, -0.1129,  0.1032]],\n",
      "\n",
      "         [[ 0.0160,  0.0915, -0.0530],\n",
      "          [ 0.0439,  0.0911,  0.0262],\n",
      "          [ 0.1032, -0.0276,  0.0134]],\n",
      "\n",
      "         [[-0.0175, -0.1062,  0.0358],\n",
      "          [-0.0294,  0.0305,  0.0873],\n",
      "          [ 0.1180,  0.0435, -0.0336]],\n",
      "\n",
      "         [[-0.0898,  0.0222, -0.0132],\n",
      "          [-0.0959,  0.0454, -0.0072],\n",
      "          [ 0.1226, -0.0402,  0.0734]],\n",
      "\n",
      "         [[-0.0533,  0.0307,  0.0449],\n",
      "          [ 0.0526, -0.0477, -0.0543],\n",
      "          [-0.1270,  0.0249,  0.0551]]],\n",
      "\n",
      "\n",
      "        [[[-0.0866, -0.0533,  0.0648],\n",
      "          [ 0.0490,  0.0146,  0.1181],\n",
      "          [ 0.0565,  0.0793, -0.0584]],\n",
      "\n",
      "         [[-0.0340,  0.0840,  0.0668],\n",
      "          [-0.0270, -0.0645, -0.1171],\n",
      "          [ 0.1059, -0.0157,  0.1020]],\n",
      "\n",
      "         [[ 0.0516,  0.0331,  0.0520],\n",
      "          [-0.0022, -0.0360,  0.1286],\n",
      "          [ 0.0103,  0.0467, -0.1122]],\n",
      "\n",
      "         [[ 0.0907, -0.0446,  0.1191],\n",
      "          [-0.0345,  0.0769, -0.0640],\n",
      "          [ 0.0290,  0.0946, -0.0466]],\n",
      "\n",
      "         [[-0.1049, -0.0079, -0.1248],\n",
      "          [-0.0889,  0.0102, -0.0298],\n",
      "          [ 0.0359, -0.0373,  0.0991]],\n",
      "\n",
      "         [[-0.0810, -0.1211, -0.0467],\n",
      "          [-0.1179,  0.0578,  0.1307],\n",
      "          [-0.0128, -0.0388, -0.0004]]],\n",
      "\n",
      "\n",
      "        [[[-0.0065, -0.0286,  0.0537],\n",
      "          [-0.1225,  0.0971, -0.0505],\n",
      "          [-0.0990,  0.0560,  0.1276]],\n",
      "\n",
      "         [[ 0.1362,  0.0673, -0.1301],\n",
      "          [ 0.1029, -0.0324,  0.1156],\n",
      "          [ 0.0649, -0.0240,  0.1147]],\n",
      "\n",
      "         [[-0.0922,  0.0826, -0.0045],\n",
      "          [ 0.1279, -0.1031,  0.0951],\n",
      "          [ 0.1007, -0.1191, -0.0148]],\n",
      "\n",
      "         [[-0.0978, -0.0529, -0.0013],\n",
      "          [ 0.0710, -0.0048, -0.1099],\n",
      "          [-0.1041, -0.1126, -0.0624]],\n",
      "\n",
      "         [[ 0.0103,  0.1006,  0.0319],\n",
      "          [-0.0354, -0.0350,  0.0857],\n",
      "          [-0.0602, -0.0357, -0.0248]],\n",
      "\n",
      "         [[-0.0904, -0.1224,  0.1380],\n",
      "          [ 0.1117,  0.1120,  0.0709],\n",
      "          [ 0.0557,  0.1206, -0.1265]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0062,  0.0248,  0.1072],\n",
      "          [ 0.0689, -0.0091,  0.0141],\n",
      "          [ 0.1151,  0.1236,  0.1070]],\n",
      "\n",
      "         [[ 0.1256, -0.0209, -0.0934],\n",
      "          [-0.0481,  0.1238, -0.1002],\n",
      "          [-0.1112,  0.1156, -0.0663]],\n",
      "\n",
      "         [[ 0.0335,  0.0855,  0.0885],\n",
      "          [-0.0929,  0.0568, -0.0335],\n",
      "          [ 0.0609, -0.1199,  0.1127]],\n",
      "\n",
      "         [[-0.0993, -0.0285,  0.0501],\n",
      "          [-0.0936, -0.0301, -0.0342],\n",
      "          [ 0.0422,  0.0408, -0.0680]],\n",
      "\n",
      "         [[ 0.0038,  0.0887,  0.0481],\n",
      "          [ 0.1311, -0.0629, -0.1285],\n",
      "          [-0.1237,  0.1362, -0.0530]],\n",
      "\n",
      "         [[ 0.0447, -0.0133,  0.0551],\n",
      "          [-0.0959, -0.0211, -0.0120],\n",
      "          [ 0.0346,  0.0027, -0.0087]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1048, -0.0220,  0.0625],\n",
      "          [ 0.0042,  0.0188,  0.0410],\n",
      "          [-0.0156, -0.0680,  0.0060]],\n",
      "\n",
      "         [[ 0.1106, -0.0063,  0.1011],\n",
      "          [-0.1270,  0.0103,  0.0452],\n",
      "          [ 0.0767, -0.1336,  0.1032]],\n",
      "\n",
      "         [[ 0.1038,  0.1054,  0.1053],\n",
      "          [ 0.0630, -0.0167,  0.1173],\n",
      "          [ 0.1251, -0.0473,  0.0568]],\n",
      "\n",
      "         [[ 0.0985,  0.0280, -0.0004],\n",
      "          [ 0.1229, -0.0851, -0.0010],\n",
      "          [-0.0616, -0.0924, -0.0297]],\n",
      "\n",
      "         [[ 0.0093,  0.0060, -0.1168],\n",
      "          [-0.0781,  0.0564,  0.0493],\n",
      "          [-0.0418, -0.0405, -0.0912]],\n",
      "\n",
      "         [[ 0.1225, -0.0116, -0.0399],\n",
      "          [-0.0897, -0.0551,  0.0204],\n",
      "          [ 0.0588,  0.0717,  0.0578]]],\n",
      "\n",
      "\n",
      "        [[[-0.0030, -0.1265, -0.0490],\n",
      "          [ 0.0354,  0.0634, -0.1038],\n",
      "          [-0.0102, -0.1226,  0.1177]],\n",
      "\n",
      "         [[ 0.0845,  0.0685,  0.0379],\n",
      "          [-0.0103, -0.1237,  0.1044],\n",
      "          [-0.1142,  0.1252,  0.0337]],\n",
      "\n",
      "         [[ 0.0064,  0.0145,  0.1269],\n",
      "          [-0.0723,  0.0621,  0.1357],\n",
      "          [-0.0065, -0.0576, -0.0227]],\n",
      "\n",
      "         [[-0.0974,  0.0839, -0.1257],\n",
      "          [ 0.0162, -0.0984,  0.1408],\n",
      "          [-0.0333,  0.1246, -0.0476]],\n",
      "\n",
      "         [[-0.1054,  0.0875,  0.0515],\n",
      "          [ 0.1079, -0.0536, -0.0994],\n",
      "          [-0.0705,  0.1172, -0.1273]],\n",
      "\n",
      "         [[-0.1051,  0.0269, -0.0273],\n",
      "          [ 0.0883,  0.0042, -0.0374],\n",
      "          [-0.0296, -0.0100,  0.1186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0137, -0.0761,  0.0058],\n",
      "          [-0.1323, -0.0483, -0.1285],\n",
      "          [-0.0950, -0.0937,  0.0573]],\n",
      "\n",
      "         [[ 0.1022,  0.0939,  0.0013],\n",
      "          [ 0.0835, -0.0893,  0.1175],\n",
      "          [ 0.0387,  0.0488,  0.0423]],\n",
      "\n",
      "         [[-0.0620, -0.1263,  0.0255],\n",
      "          [ 0.0616,  0.0402,  0.0723],\n",
      "          [-0.0354, -0.0986, -0.0550]],\n",
      "\n",
      "         [[ 0.0938, -0.0635, -0.0673],\n",
      "          [-0.0926,  0.0528,  0.0699],\n",
      "          [ 0.1107,  0.0928,  0.0004]],\n",
      "\n",
      "         [[ 0.0464,  0.0643,  0.0898],\n",
      "          [ 0.0836, -0.0924,  0.0105],\n",
      "          [-0.0048,  0.0735, -0.0770]],\n",
      "\n",
      "         [[-0.0479,  0.0111,  0.0616],\n",
      "          [-0.1195, -0.0649, -0.0603],\n",
      "          [ 0.0572, -0.0946, -0.0325]]],\n",
      "\n",
      "\n",
      "        [[[-0.0244,  0.0611,  0.0273],\n",
      "          [-0.0807,  0.1315,  0.0811],\n",
      "          [-0.1202, -0.0125,  0.0039]],\n",
      "\n",
      "         [[ 0.0516, -0.0097,  0.0469],\n",
      "          [ 0.1011,  0.0602,  0.0708],\n",
      "          [-0.1174, -0.0210,  0.0930]],\n",
      "\n",
      "         [[ 0.0990, -0.0645, -0.0375],\n",
      "          [-0.0428, -0.1056,  0.0760],\n",
      "          [ 0.0138, -0.0213, -0.1272]],\n",
      "\n",
      "         [[ 0.0893, -0.0124, -0.0284],\n",
      "          [ 0.0241,  0.0199,  0.0906],\n",
      "          [-0.1064, -0.1216,  0.1258]],\n",
      "\n",
      "         [[-0.1132,  0.1398, -0.1124],\n",
      "          [ 0.0659,  0.0266,  0.1108],\n",
      "          [-0.1339, -0.1001, -0.0594]],\n",
      "\n",
      "         [[-0.0494,  0.0088, -0.0306],\n",
      "          [ 0.0280,  0.0562,  0.0782],\n",
      "          [-0.1010,  0.0799,  0.0140]]],\n",
      "\n",
      "\n",
      "        [[[-0.0930, -0.0957,  0.0626],\n",
      "          [ 0.0630,  0.0869,  0.0643],\n",
      "          [-0.0407, -0.0270,  0.1136]],\n",
      "\n",
      "         [[ 0.0655, -0.0817, -0.0405],\n",
      "          [ 0.0202,  0.0179,  0.1044],\n",
      "          [-0.0218,  0.0342, -0.0829]],\n",
      "\n",
      "         [[-0.0638,  0.0351,  0.1177],\n",
      "          [-0.0125,  0.0068, -0.0231],\n",
      "          [ 0.0730, -0.1029, -0.0506]],\n",
      "\n",
      "         [[ 0.0883,  0.0591, -0.0369],\n",
      "          [-0.1030, -0.0439,  0.1036],\n",
      "          [ 0.1152,  0.1201,  0.0676]],\n",
      "\n",
      "         [[ 0.1166,  0.0974, -0.0027],\n",
      "          [-0.1149,  0.1246,  0.0948],\n",
      "          [ 0.0590,  0.0775, -0.0086]],\n",
      "\n",
      "         [[ 0.1356, -0.0463, -0.0366],\n",
      "          [-0.0585, -0.0459,  0.0611],\n",
      "          [-0.1171, -0.0840,  0.0423]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0345,  0.0319, -0.0585],\n",
      "          [-0.0031, -0.0519, -0.0748],\n",
      "          [-0.0168,  0.0168,  0.0543]],\n",
      "\n",
      "         [[-0.1081,  0.1255, -0.0973],\n",
      "          [-0.1080, -0.0011,  0.1321],\n",
      "          [-0.0578, -0.0743, -0.0745]],\n",
      "\n",
      "         [[-0.0120,  0.1327,  0.0189],\n",
      "          [ 0.1211,  0.0165, -0.0337],\n",
      "          [ 0.0173,  0.1093,  0.1044]],\n",
      "\n",
      "         [[-0.0612,  0.1318,  0.1322],\n",
      "          [ 0.1204, -0.0274,  0.1415],\n",
      "          [ 0.0527,  0.0026, -0.0654]],\n",
      "\n",
      "         [[-0.0847,  0.0939,  0.1242],\n",
      "          [-0.0170, -0.0162,  0.0806],\n",
      "          [-0.1031,  0.0869, -0.0271]],\n",
      "\n",
      "         [[ 0.1347, -0.0233, -0.0710],\n",
      "          [-0.0233, -0.0922, -0.0595],\n",
      "          [-0.0460,  0.0652,  0.0631]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1208,  0.0485,  0.1225,  0.0310, -0.0635,  0.0753, -0.0553, -0.0571,\n",
      "        -0.1026,  0.0892, -0.0204,  0.1408, -0.0659,  0.1198,  0.0693,  0.1293],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 4.9928e-03,  2.9912e-02,  6.7025e-03,  ...,  7.9095e-03,\n",
      "         -4.1032e-02, -2.5125e-02],\n",
      "        [ 4.0371e-02, -1.9010e-02,  1.0451e-02,  ..., -3.6076e-02,\n",
      "         -1.1835e-02,  3.3362e-02],\n",
      "        [-1.5855e-02, -3.6503e-02, -8.0732e-03,  ...,  2.5670e-02,\n",
      "          2.8059e-03, -6.7779e-04],\n",
      "        ...,\n",
      "        [-2.4612e-02, -6.5252e-05, -9.4371e-03,  ..., -3.1438e-02,\n",
      "          2.0348e-03,  5.8149e-03],\n",
      "        [ 4.3133e-02,  2.9967e-02,  5.5420e-03,  ...,  2.4947e-02,\n",
      "         -9.7355e-03,  2.8304e-02],\n",
      "        [-2.5216e-05,  2.3177e-02, -4.6969e-03,  ..., -5.8874e-03,\n",
      "         -4.3937e-02,  2.8880e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0153, -0.0391, -0.0290, -0.0189, -0.0182, -0.0236, -0.0380, -0.0300,\n",
      "        -0.0391, -0.0208, -0.0118, -0.0345, -0.0082, -0.0328,  0.0169,  0.0253,\n",
      "        -0.0362,  0.0094, -0.0326,  0.0200,  0.0424,  0.0389,  0.0373, -0.0063,\n",
      "        -0.0022,  0.0363, -0.0014,  0.0360, -0.0198,  0.0054, -0.0272, -0.0317,\n",
      "        -0.0065, -0.0264,  0.0320, -0.0135,  0.0040,  0.0234, -0.0137,  0.0101,\n",
      "        -0.0122, -0.0255,  0.0345,  0.0089,  0.0234,  0.0412,  0.0213,  0.0421,\n",
      "         0.0002, -0.0181, -0.0037, -0.0108,  0.0126,  0.0166,  0.0396, -0.0015,\n",
      "        -0.0260, -0.0290,  0.0327,  0.0023,  0.0319,  0.0269, -0.0169,  0.0173,\n",
      "        -0.0402,  0.0038,  0.0378,  0.0059, -0.0122, -0.0417,  0.0403, -0.0107,\n",
      "         0.0261,  0.0069,  0.0166, -0.0244, -0.0255,  0.0198, -0.0278,  0.0428,\n",
      "        -0.0271, -0.0092,  0.0125,  0.0181, -0.0019, -0.0123,  0.0252, -0.0295,\n",
      "         0.0331,  0.0340,  0.0175, -0.0325, -0.0096, -0.0218,  0.0118,  0.0125,\n",
      "        -0.0029, -0.0042, -0.0293, -0.0318,  0.0290,  0.0185,  0.0181, -0.0284,\n",
      "         0.0194,  0.0319, -0.0005, -0.0175,  0.0305, -0.0119,  0.0420, -0.0180,\n",
      "        -0.0264, -0.0210, -0.0358, -0.0339, -0.0033,  0.0410, -0.0127,  0.0335],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0185,  0.0498, -0.0649,  ...,  0.0151,  0.0773, -0.0547],\n",
      "        [-0.0388,  0.0836, -0.0415,  ..., -0.0742,  0.0151,  0.0195],\n",
      "        [ 0.0558, -0.0527, -0.0578,  ..., -0.0851,  0.0335, -0.0478],\n",
      "        ...,\n",
      "        [-0.0565,  0.0167, -0.0194,  ..., -0.0717,  0.0700, -0.0131],\n",
      "        [-0.0616,  0.0533, -0.0210,  ...,  0.0606,  0.0368,  0.0220],\n",
      "        [ 0.0174,  0.0434,  0.0156,  ...,  0.0292, -0.0239,  0.0241]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0121, -0.0260,  0.0072,  0.0190, -0.0406, -0.0650,  0.0265,  0.0506,\n",
      "         0.0010,  0.0194, -0.0355, -0.0433,  0.0029, -0.0732,  0.0463, -0.0692,\n",
      "         0.0516,  0.0800, -0.0116,  0.0484, -0.0323,  0.0740, -0.0850,  0.0292,\n",
      "        -0.0574,  0.0495, -0.0557, -0.0008, -0.0790, -0.0402, -0.0125, -0.0359,\n",
      "        -0.0563, -0.0475, -0.0393,  0.0552,  0.0949, -0.0432,  0.0897,  0.1038,\n",
      "         0.0047, -0.0437, -0.0276, -0.0681,  0.0573,  0.0870, -0.0629,  0.0582,\n",
      "        -0.0098,  0.0517,  0.0020,  0.0854,  0.0194,  0.0768, -0.0270, -0.0523,\n",
      "        -0.0563,  0.0600, -0.0557,  0.0238, -0.0110,  0.0252,  0.0818, -0.0554,\n",
      "        -0.0840, -0.0715,  0.0785, -0.0382,  0.0084,  0.0104, -0.0186,  0.0169,\n",
      "         0.0834, -0.0532,  0.0370,  0.0525, -0.0268, -0.0685,  0.0066,  0.0100,\n",
      "        -0.0605, -0.0526, -0.0234, -0.0204], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0065,  0.0323,  0.0730, -0.0350,  0.1067,  0.0021, -0.0765,  0.0093,\n",
      "          0.0292, -0.0290,  0.0625, -0.0428,  0.0513,  0.0007, -0.0614, -0.0016,\n",
      "          0.0443,  0.0103, -0.0981, -0.0082,  0.0351,  0.0288, -0.0441,  0.0767,\n",
      "         -0.0842,  0.0743, -0.0175, -0.0636,  0.0063,  0.0021, -0.0622,  0.0154,\n",
      "         -0.0345, -0.0494, -0.0953,  0.0608,  0.0362,  0.0925,  0.0822,  0.0061,\n",
      "          0.0520,  0.0515, -0.0395, -0.0672, -0.0103,  0.0040, -0.0246, -0.0754,\n",
      "         -0.0249,  0.0643,  0.0306,  0.0314,  0.0837, -0.0050,  0.0377, -0.0211,\n",
      "         -0.0837,  0.0770, -0.1086,  0.0380, -0.1009, -0.0590, -0.0742,  0.1104,\n",
      "          0.0093,  0.0092, -0.0210,  0.1074,  0.0084,  0.0966,  0.0851,  0.0971,\n",
      "          0.0340,  0.0609, -0.0501, -0.1007,  0.0389, -0.0403,  0.1017, -0.0886,\n",
      "         -0.0585, -0.0366, -0.0324, -0.1046],\n",
      "        [-0.0042, -0.0374, -0.0342,  0.0640,  0.0323, -0.0165,  0.0976,  0.1095,\n",
      "          0.0664,  0.0135, -0.0553,  0.0528,  0.0104,  0.0243,  0.0630, -0.0566,\n",
      "         -0.0385,  0.0335,  0.0743, -0.0822,  0.0866,  0.0822, -0.0670, -0.0558,\n",
      "         -0.0194,  0.0267,  0.0348,  0.0574,  0.0617,  0.0656,  0.0710,  0.0037,\n",
      "          0.0804, -0.0031, -0.0561,  0.0164,  0.1214, -0.0517, -0.0787, -0.0187,\n",
      "          0.1195,  0.0496, -0.0793, -0.0401, -0.0110,  0.0071, -0.0393,  0.0920,\n",
      "         -0.0085, -0.0625, -0.0325,  0.0928,  0.0923,  0.0908, -0.0347, -0.1053,\n",
      "          0.0824,  0.0537,  0.0676,  0.0222, -0.0806,  0.0121, -0.0128, -0.0565,\n",
      "         -0.0699, -0.0656, -0.0861,  0.0153,  0.0168,  0.0217,  0.0715, -0.0566,\n",
      "         -0.0830, -0.0948,  0.1351,  0.0403,  0.1123,  0.0781, -0.0979, -0.0861,\n",
      "         -0.0341,  0.0024,  0.0656, -0.0447],\n",
      "        [-0.0877,  0.0708, -0.0076,  0.0464, -0.1027, -0.0949,  0.0395,  0.0994,\n",
      "          0.0880,  0.1001, -0.1026,  0.0196, -0.1024,  0.0321, -0.0130, -0.0649,\n",
      "          0.0173, -0.0386, -0.0429, -0.0264, -0.0589, -0.0848, -0.0816,  0.0982,\n",
      "         -0.0769, -0.0850,  0.0194,  0.1008,  0.1070, -0.0187,  0.0483, -0.0381,\n",
      "         -0.0200, -0.0517,  0.1063, -0.0410,  0.0832,  0.0978, -0.0174,  0.0032,\n",
      "          0.0997, -0.0620, -0.1070, -0.1017, -0.0351, -0.0746, -0.0333, -0.0562,\n",
      "          0.0681,  0.0057, -0.0343, -0.0911, -0.0426, -0.0293,  0.0742, -0.0463,\n",
      "         -0.0125, -0.0734, -0.1009,  0.0741, -0.1040, -0.0896, -0.0266, -0.0378,\n",
      "         -0.0425,  0.0141,  0.0225,  0.0487, -0.0841, -0.0573, -0.0877, -0.0065,\n",
      "         -0.0703,  0.0385,  0.1116,  0.0732,  0.0740, -0.0526,  0.0034,  0.0310,\n",
      "         -0.0931,  0.0385, -0.0765,  0.0655],\n",
      "        [ 0.0289,  0.0918, -0.0767,  0.0347,  0.0295, -0.0348, -0.0351,  0.0206,\n",
      "         -0.0181,  0.0581,  0.0723,  0.0713, -0.0531, -0.0974, -0.0358,  0.0936,\n",
      "         -0.0238,  0.0112, -0.0914, -0.0467,  0.1025,  0.0135, -0.0499, -0.0740,\n",
      "         -0.0710,  0.0659,  0.0454,  0.0067,  0.0656,  0.0145,  0.0409, -0.1078,\n",
      "         -0.0934, -0.0375, -0.1064,  0.0674, -0.0637,  0.0952,  0.0408, -0.0279,\n",
      "         -0.1105, -0.0600,  0.0315,  0.0671,  0.0613, -0.0219,  0.0135,  0.0285,\n",
      "          0.0643,  0.0521,  0.1003,  0.0939, -0.0756, -0.0557,  0.0342,  0.0133,\n",
      "          0.0457, -0.0285, -0.0460,  0.0803,  0.0972,  0.0452,  0.0130, -0.0989,\n",
      "          0.0137, -0.0718, -0.0168,  0.1006,  0.0675, -0.1081, -0.1042,  0.0695,\n",
      "          0.0357, -0.0595,  0.0477,  0.0088,  0.0605, -0.0865,  0.1041, -0.1058,\n",
      "          0.0321,  0.0042,  0.0364,  0.1033],\n",
      "        [-0.0146, -0.0983,  0.0306, -0.0735,  0.0869,  0.0600, -0.0864,  0.0407,\n",
      "          0.0083, -0.0233, -0.0476,  0.0898,  0.0161, -0.0240, -0.0611,  0.0650,\n",
      "          0.0797, -0.0597,  0.0856,  0.0474, -0.0832, -0.0438,  0.0051, -0.0022,\n",
      "          0.0824,  0.0793,  0.0869,  0.0857, -0.0416,  0.0986,  0.1004, -0.0031,\n",
      "          0.0020, -0.0731, -0.0098, -0.0358, -0.0736, -0.0418, -0.0263, -0.0922,\n",
      "          0.0196,  0.0864, -0.0016,  0.0398,  0.0150, -0.0332,  0.0990, -0.0198,\n",
      "          0.0520,  0.0683, -0.0900, -0.0174,  0.0492, -0.0852, -0.0811, -0.0362,\n",
      "         -0.0068, -0.0017,  0.0941, -0.1032,  0.1000,  0.0634, -0.0760, -0.0010,\n",
      "          0.0035, -0.0400,  0.0448,  0.0137, -0.0585, -0.0867,  0.0978,  0.0259,\n",
      "          0.0803, -0.0770, -0.0696, -0.1032, -0.0362,  0.0621,  0.0631, -0.0961,\n",
      "         -0.0592,  0.0377,  0.0178,  0.0268],\n",
      "        [ 0.0939,  0.0257,  0.0195, -0.0557,  0.0581,  0.0351,  0.0952,  0.0745,\n",
      "          0.0495,  0.0015, -0.0742,  0.0229, -0.0457,  0.0415, -0.0391,  0.0990,\n",
      "          0.0273,  0.0870, -0.0872,  0.0362, -0.0290, -0.1074,  0.0624, -0.0568,\n",
      "         -0.0380,  0.0035,  0.0525,  0.0212,  0.1017, -0.0822, -0.1002,  0.0383,\n",
      "         -0.0710, -0.0602,  0.0977, -0.0111, -0.1282, -0.0184,  0.0330, -0.1282,\n",
      "         -0.0997,  0.0996,  0.0995,  0.0709, -0.0739,  0.0502,  0.0910,  0.0955,\n",
      "          0.0643, -0.0663,  0.0226, -0.0764, -0.0984,  0.0581,  0.0081,  0.0609,\n",
      "         -0.0225, -0.1083, -0.0778,  0.0607, -0.0736, -0.1015,  0.0162, -0.0906,\n",
      "         -0.0625, -0.0086,  0.0848, -0.0756, -0.0679,  0.0615,  0.0420,  0.0979,\n",
      "          0.0959, -0.0631, -0.0494, -0.0021, -0.0088,  0.0161, -0.0355,  0.0280,\n",
      "          0.0266, -0.0275, -0.0023,  0.0427],\n",
      "        [ 0.0583,  0.0926,  0.0267,  0.0092, -0.0429,  0.0753, -0.0639, -0.0150,\n",
      "         -0.0993,  0.0334,  0.1081, -0.0987, -0.0438, -0.0078,  0.0775, -0.0373,\n",
      "          0.0855,  0.0048, -0.0385,  0.0175, -0.0683, -0.0381,  0.0912, -0.0688,\n",
      "          0.0037,  0.0019,  0.0268,  0.0764,  0.0860, -0.0845, -0.0410, -0.0086,\n",
      "          0.0923,  0.0558,  0.0461,  0.1062, -0.1103,  0.0230,  0.0738,  0.0694,\n",
      "         -0.1083,  0.0270, -0.0858,  0.0252,  0.1051, -0.0569,  0.1066, -0.0413,\n",
      "          0.0043, -0.0698,  0.1091, -0.0559,  0.0906, -0.0276,  0.0609,  0.0930,\n",
      "          0.0073,  0.0962,  0.0047,  0.0586, -0.0258, -0.0262,  0.0182,  0.0195,\n",
      "         -0.0443, -0.0515, -0.0305, -0.1072, -0.0604, -0.0785, -0.0301, -0.0706,\n",
      "          0.0585, -0.0134,  0.0033, -0.0134,  0.0481, -0.0954,  0.0177, -0.0902,\n",
      "         -0.0224, -0.0672, -0.0747, -0.0104],\n",
      "        [-0.0104, -0.0148, -0.0116, -0.0012,  0.0750,  0.0173, -0.0968, -0.0199,\n",
      "          0.0912,  0.0570,  0.0111, -0.0904, -0.0793, -0.0435,  0.0056,  0.0635,\n",
      "          0.0469, -0.0641,  0.0830, -0.0919,  0.0529, -0.0794,  0.0262,  0.1029,\n",
      "         -0.0767, -0.0828,  0.0645, -0.0249, -0.0138,  0.0607,  0.0445, -0.0124,\n",
      "          0.1049, -0.1023,  0.0372,  0.0521,  0.1042, -0.1032, -0.0520, -0.0730,\n",
      "          0.0192, -0.1026, -0.0975, -0.0553,  0.0764, -0.0919,  0.0432,  0.0296,\n",
      "         -0.0962, -0.0345, -0.0069,  0.0373, -0.1018, -0.0808, -0.0629, -0.0951,\n",
      "          0.0912,  0.0061, -0.0518,  0.0791, -0.0380,  0.0355, -0.0415, -0.0680,\n",
      "         -0.0836,  0.1033, -0.1050,  0.0922,  0.0663,  0.0778,  0.1049, -0.0229,\n",
      "          0.1003,  0.1006, -0.0841,  0.0897,  0.0523,  0.0437, -0.0074, -0.0525,\n",
      "          0.0683,  0.0166, -0.0477, -0.0308],\n",
      "        [ 0.0256,  0.1090,  0.0217,  0.1024, -0.0053,  0.0032,  0.0866,  0.0255,\n",
      "          0.0881, -0.1042, -0.0277,  0.1082,  0.0639,  0.1075,  0.0578,  0.0764,\n",
      "         -0.0554,  0.0818, -0.0009,  0.0096, -0.0690,  0.1005, -0.0961,  0.0195,\n",
      "          0.0531,  0.0531, -0.0647, -0.0646, -0.1069, -0.0986, -0.0920, -0.0356,\n",
      "         -0.0752, -0.0949, -0.0064,  0.0142,  0.0984,  0.0877,  0.0225, -0.0294,\n",
      "         -0.0704,  0.1019, -0.0932,  0.0597, -0.0676, -0.0559, -0.0163,  0.0917,\n",
      "          0.0374, -0.0373, -0.0850,  0.1008,  0.1063, -0.0308,  0.1020, -0.1060,\n",
      "          0.0131, -0.1039, -0.0616, -0.0482, -0.0809, -0.0325,  0.0277, -0.0123,\n",
      "         -0.0657, -0.0774,  0.0039, -0.0007, -0.0444,  0.0391, -0.0334,  0.0280,\n",
      "         -0.0631,  0.0675,  0.0596, -0.0474, -0.0290, -0.0889,  0.0970, -0.0196,\n",
      "         -0.0224,  0.0428, -0.0732, -0.0374],\n",
      "        [ 0.1057,  0.0423, -0.0561,  0.0565, -0.0589,  0.0952,  0.0529, -0.0134,\n",
      "         -0.0334, -0.0859, -0.0133, -0.0564,  0.0759,  0.0263,  0.0336, -0.0267,\n",
      "         -0.0658,  0.0902,  0.0340, -0.0489, -0.0484, -0.0670, -0.1070, -0.0399,\n",
      "         -0.0168,  0.0361,  0.0632, -0.0069, -0.0747,  0.0481, -0.0997, -0.0504,\n",
      "         -0.0692,  0.0617, -0.0857,  0.0855,  0.0307, -0.0129, -0.0514,  0.1065,\n",
      "          0.0542,  0.0650,  0.0316,  0.0974, -0.0811,  0.0367, -0.0824, -0.0641,\n",
      "          0.0313, -0.0168,  0.1036, -0.0291,  0.0013, -0.0090, -0.0828, -0.0971,\n",
      "         -0.0758,  0.0465, -0.0433, -0.0569,  0.0718,  0.0603,  0.0441, -0.0473,\n",
      "         -0.0744,  0.0285, -0.0690,  0.1016,  0.0729, -0.1028, -0.0841,  0.0578,\n",
      "         -0.0152, -0.1021,  0.0874,  0.0685, -0.0198,  0.0563, -0.0105,  0.0106,\n",
      "          0.0948,  0.0808, -0.0299,  0.0458]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0468,  0.0272, -0.0122, -0.0467, -0.0642, -0.0423, -0.0949, -0.0412,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.0675,  0.1049], requires_grad=True)]\n",
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0022, -0.0382, -0.0923, -0.0186,  0.0132,  0.0430, -0.0700, -0.1009,\n",
      "         -0.0829,  0.1326]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,1,32,32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5250,  0.5543, -0.2118, -0.5746, -1.2649, -1.9040,  0.8082,  1.1861,\n",
      "        -1.0621,  0.8983])\n",
      "tensor([[-0.5250,  0.5543, -0.2118, -0.5746, -1.2649, -1.9040,  0.8082,  1.1861,\n",
      "         -1.0621,  0.8983]])\n",
      "tensor(0.7541, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "print(target)\n",
    "target = target.view(1,-1)    # a.view(x,y) 将a转换为x行y列的tensor 参数不可为空 若为-1则该位置数据由其他位置推断\n",
    "print(target)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output,target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input -> conv2d 卷积函数 -> relu线性整流函数 激活函数 -> maxpool2d 池化层 -> conv2d 卷积函数 -> relu线性整流函数 激活函数 \n",
    "#       -> maxpool2d 池化层  -> view resize -> linear 线性层 -> relu 激活函数 -> linear 线性层 -> relu 激活函数 -> linear 线性层\n",
    "#       -> MSELoss 损失函数\n",
    "#       ->loss 损失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000000004FE5668>\n",
      "<AddmmBackward object at 0x0000000004FE5668>\n",
      "<AccumulateGrad object at 0x0000000007790A90>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)   # mseloss\n",
    "print(loss.grad_fn.next_functions[0][0])   # linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) #relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0098, -0.0080, -0.0280, -0.0296, -0.0088, -0.0096])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"conv1.bias.grad after backward\")\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = weight - learning_rate * gradient\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6849, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# creat your optimizer\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.01)\n",
    "\n",
    "# in your training loop\n",
    "optimizer.zero_grad()   #zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output,target)\n",
    "loss.backward()\n",
    "optimizer.step()    # does the update \n",
    "\n",
    "print(loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
